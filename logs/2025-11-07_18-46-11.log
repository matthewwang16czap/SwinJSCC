W1107 18:46:31.952000 50982 site-packages/torch/distributed/run.py:793] 
W1107 18:46:31.952000 50982 site-packages/torch/distributed/run.py:793] *****************************************
W1107 18:46:31.952000 50982 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1107 18:46:31.952000 50982 site-packages/torch/distributed/run.py:793] *****************************************
WARNING: Logging before InitGoogleLogging() is written to STDERR
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1107 18:47:19.446287 51002 ProcessGroupNCCL.cpp:922] [PG ID 0 PG GUID 0 Rank 1] ProcessGroupNCCL initialization options: size: 2, global rank: 1, TIMEOUT(ms): 600000, USE_HIGH_PRIORITY_STREAM: 0, SPLIT_FROM: 0, SPLIT_COLOR: 0, PG Name: 0
I1107 18:47:19.446264 51001 ProcessGroupNCCL.cpp:922] [PG ID 0 PG GUID 0 Rank 0] ProcessGroupNCCL initialization options: size: 2, global rank: 0, TIMEOUT(ms): 600000, USE_HIGH_PRIORITY_STREAM: 0, SPLIT_FROM: 0, SPLIT_COLOR: 0, PG Name: 0
I1107 18:47:19.450389 51002 ProcessGroupNCCL.cpp:931] [PG ID 0 PG GUID 0 Rank 1] ProcessGroupNCCL environments: NCCL version: 2.18.3, TORCH_NCCL_ASYNC_ERROR_HANDLING: 1, TORCH_NCCL_DUMP_ON_TIMEOUT: 0, TORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC: 60000, TORCH_NCCL_DESYNC_DEBUG: 0, TORCH_NCCL_ENABLE_TIMING: 0, TORCH_NCCL_BLOCKING_WAIT: 0, TORCH_DISTRIBUTED_DEBUG: OFF, TORCH_NCCL_ENABLE_MONITORING: 1, TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC: 480, TORCH_NCCL_TRACE_BUFFER_SIZE: 0, TORCH_NCCL_COORD_CHECK_MILSEC: 1000, TORCH_NCCL_NAN_CHECK: 0, TORCH_NCCL_CUDA_EVENT_CACHE: 0, TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN: 1
I1107 18:47:19.450413 51001 ProcessGroupNCCL.cpp:931] [PG ID 0 PG GUID 0 Rank 0] ProcessGroupNCCL environments: NCCL version: 2.18.3, TORCH_NCCL_ASYNC_ERROR_HANDLING: 1, TORCH_NCCL_DUMP_ON_TIMEOUT: 0, TORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC: 60000, TORCH_NCCL_DESYNC_DEBUG: 0, TORCH_NCCL_ENABLE_TIMING: 0, TORCH_NCCL_BLOCKING_WAIT: 0, TORCH_DISTRIBUTED_DEBUG: OFF, TORCH_NCCL_ENABLE_MONITORING: 1, TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC: 480, TORCH_NCCL_TRACE_BUFFER_SIZE: 0, TORCH_NCCL_COORD_CHECK_MILSEC: 1000, TORCH_NCCL_NAN_CHECK: 0, TORCH_NCCL_CUDA_EVENT_CACHE: 0, TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN: 1
2025-11-07 18:47:20,537 - INFO] {'seed': 42, 'pass_channel': True, 'CUDA': True, 'device': device(type='cuda', index=0), 'norm': False, 'print_step': 100, 'plot_step': 10000, 'filename': '2025-11-07_18-47-19', 'workdir': './history/2025-11-07_18-47-19', 'homedir': '/public/home/sihanwang/', 'log': './history/2025-11-07_18-47-19/Log_2025-11-07_18-47-19.log', 'samples': './history/2025-11-07_18-47-19/samples', 'models': './history/2025-11-07_18-47-19/models', 'logger': <Logger Deep joint source channel coder (INFO)>, 'normalize': False, 'learning_rate': 0.0001, 'alpha_losses': [10, 2, 0.2, 0.5, 1, 0.05], 'tot_epoch': 10000000, 'denoise': True, 'denoise_training': True, 'save_model_freq': 100, 'image_dims': (3, 256, 256), 'train_data_dir': ['/public/home/sihanwang/datasets/DIV2K//clic2020/**', '/public/home/sihanwang/datasets/DIV2K//clic2021/train', '/public/home/sihanwang/datasets/DIV2K//clic2021/valid', '/public/home/sihanwang/datasets/DIV2K//clic2022/val', '/public/home/sihanwang/datasets/DIV2K//DIV2K_train_HR', '/public/home/sihanwang/datasets/DIV2K//DIV2K_valid_HR'], 'batch_size': 16, 'downsample': 4, 'test_data_dir': ['/public/home/sihanwang/datasets/Kodak/'], 'channel_number': None, 'encoder_kwargs': {'model': 'SwinJSCC_w/_SAandRA', 'img_size': (256, 256), 'patch_size': 2, 'in_chans': 3, 'embed_dims': [128, 192, 256, 320], 'depths': [2, 2, 6, 2], 'num_heads': [4, 6, 8, 10], 'C': None, 'window_size': 8, 'mlp_ratio': 4.0, 'qkv_bias': True, 'qk_scale': None, 'norm_layer': <class 'torch.nn.modules.normalization.LayerNorm'>, 'patch_norm': True}, 'decoder_kwargs': {'model': 'SwinJSCC_w/_SAandRA', 'img_size': (256, 256), 'embed_dims': [320, 256, 192, 128], 'depths': [2, 6, 2, 2], 'num_heads': [10, 8, 6, 4], 'C': None, 'window_size': 8, 'mlp_ratio': 4.0, 'qkv_bias': True, 'qk_scale': None, 'norm_layer': <class 'torch.nn.modules.normalization.LayerNorm'>, 'patch_norm': True}, 'device_id': 0}
Encoder Encoder   dim=3, input_resolution=(256, 256), depth=2dim=3, input_resolution=(256, 256), depth=2

Encoder Encoder   dim=128, input_resolution=(128, 128), depth=2dim=128, input_resolution=(128, 128), depth=2

Encoder Encoder   dim=192, input_resolution=(64, 64), depth=6dim=192, input_resolution=(64, 64), depth=6

Encoder Encoder   dim=256, input_resolution=(32, 32), depth=2dim=256, input_resolution=(32, 32), depth=2

Decoder  dim=320, input_resolution=(16, 16), depth=2
Decoder  dim=320, input_resolution=(16, 16), depth=2
Decoder Decoder   dim=256, input_resolution=(32, 32), depth=6dim=256, input_resolution=(32, 32), depth=6

Decoder Decoder   dim=192, input_resolution=(64, 64), depth=2dim=192, input_resolution=(64, 64), depth=2

Decoder Decoder   dim=128, input_resolution=(128, 128), depth=2dim=128, input_resolution=(128, 128), depth=2

2025-11-07 18:47:21,097 - INFO] Network config: 
2025-11-07 18:47:21,097 - INFO] Encoder: 
2025-11-07 18:47:21,097 - INFO] {'model': 'SwinJSCC_w/_SAandRA', 'img_size': (256, 256), 'patch_size': 2, 'in_chans': 3, 'embed_dims': [128, 192, 256, 320], 'depths': [2, 2, 6, 2], 'num_heads': [4, 6, 8, 10], 'C': None, 'window_size': 8, 'mlp_ratio': 4.0, 'qkv_bias': True, 'qk_scale': None, 'norm_layer': <class 'torch.nn.modules.normalization.LayerNorm'>, 'patch_norm': True}
2025-11-07 18:47:21,098 - INFO] Decoder: 
2025-11-07 18:47:21,098 - INFO] {'model': 'SwinJSCC_w/_SAandRA', 'img_size': (256, 256), 'embed_dims': [320, 256, 192, 128], 'depths': [2, 6, 2, 2], 'num_heads': [10, 8, 6, 4], 'C': None, 'window_size': 8, 'mlp_ratio': 4.0, 'qkv_bias': True, 'qk_scale': None, 'norm_layer': <class 'torch.nn.modules.normalization.LayerNorm'>, 'patch_norm': True}
2025-11-07 18:47:21,113 - INFO] 【Channel】: Built awgn channel, SNR 1,4,7,10,13 dB.
/public/home/sihanwang/projects/SwinJSCC/utils.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained = torch.load(model_path)
/public/home/sihanwang/projects/SwinJSCC/utils.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained = torch.load(model_path)
I1107 18:47:22.909422 51001 ProcessGroupNCCL.cpp:2279] [PG ID 0 PG GUID 0(default_pg) Rank 0] ProcessGroupNCCL broadcast unique ID through store took 0.106686 ms
I1107 18:47:22.909487 51002 ProcessGroupNCCL.cpp:2279] [PG ID 0 PG GUID 0(default_pg) Rank 1] ProcessGroupNCCL broadcast unique ID through store took 35.7715 ms
I1107 18:47:23.148905 51002 ProcessGroupNCCL.cpp:2318] [PG ID 0 PG GUID 0(default_pg) Rank 1] ProcessGroupNCCL created ncclComm_ 0x17b4b0a0 on CUDA device: 
I1107 18:47:23.148906 51001 ProcessGroupNCCL.cpp:2318] [PG ID 0 PG GUID 0(default_pg) Rank 0] ProcessGroupNCCL created ncclComm_ 0x16c4c0b0 on CUDA device:  
I1107 18:47:23.149039 51002 ProcessGroupNCCL.cpp:2323] [PG ID 0 PG GUID 0(default_pg) Rank 1] NCCL_DEBUG: N/A
I1107 18:47:23.149085 51001 ProcessGroupNCCL.cpp:2323] [PG ID 0 PG GUID 0(default_pg) Rank 0] NCCL_DEBUG: N/A
/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at /home/pytorch/aten/src/ATen/Context.cpp:296.)
  return F.linear(input, self.weight, self.bias)
/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at /home/pytorch/aten/src/ATen/Context.cpp:296.)
  return F.linear(input, self.weight, self.bias)
MIOpen(HIP): Warning [Start] epoll_wait error Interrupted system call
MIOpen(HIP): Warning [Start] epoll_wait error Interrupted system call
2025-11-07 18:49:47,047 - INFO] [Epoch 3 | Step 100] Loss 4.9835 (4.3012) | CBR 0.0208 (0.0729) | SNR 4.00 (7.19) | PSNR(recon) 7.405 (8.117) | MSSSIM(recon) 0.230 (0.166) | PSNR(no-noise) 81.366 (80.470) | MSSSIM(no-noise) 0.976 (0.981) | Orth 0.0325 | MSE 1.8640 | MeanReg 0.005613 | Self 1.8596 | NoNoiseRecon 30.8024 | Recon 11819.5498
2025-11-07 18:51:53,851 - INFO] [Epoch 7 | Step 200] Loss 3.5754 (4.6559) | CBR 0.1250 (0.0781) | SNR 10.00 (7.00) | PSNR(recon) 7.558 (7.825) | MSSSIM(recon) 0.103 (0.182) | PSNR(no-noise) 81.119 (79.959) | MSSSIM(no-noise) 0.989 (0.979) | Orth 0.0069 | MSE 1.4029 | MeanReg 0.007021 | Self 1.3988 | NoNoiseRecon 32.5280 | Recon 11408.8730
2025-11-07 18:53:53,643 - INFO] [Epoch 10 | Step 300] Loss 2.5629 (4.1688) | CBR 0.1250 (0.0760) | SNR 13.00 (6.70) | PSNR(recon) 10.010 (8.974) | MSSSIM(recon) 0.165 (0.177) | PSNR(no-noise) 84.317 (80.190) | MSSSIM(no-noise) 0.992 (0.982) | Orth 0.0090 | MSE 0.9905 | MeanReg 0.008025 | Self 0.9810 | NoNoiseRecon 15.6196 | Recon 6487.7554
2025-11-07 18:56:00,798 - INFO] [Epoch 14 | Step 400] Loss 8.1086 (5.9560) | CBR 0.0208 (0.0443) | SNR 10.00 (7.38) | PSNR(recon) 8.829 (8.870) | MSSSIM(recon) 0.235 (0.190) | PSNR(no-noise) 74.082 (77.963) | MSSSIM(no-noise) 0.959 (0.974) | Orth 0.0429 | MSE 3.0881 | MeanReg 0.006945 | Self 3.0034 | NoNoiseRecon 164.9338 | Recon 8514.5381
2025-11-07 18:57:57,356 - INFO] [Epoch 17 | Step 500] Loss 7.3665 (4.9032) | CBR 0.0208 (0.0677) | SNR 7.00 (7.25) | PSNR(recon) 9.355 (9.251) | MSSSIM(recon) 0.255 (0.192) | PSNR(no-noise) 74.691 (79.166) | MSSSIM(no-noise) 0.956 (0.977) | Orth 0.0477 | MSE 2.7773 | MeanReg 0.005949 | Self 2.6670 | NoNoiseRecon 143.5528 | Recon 7542.9917
2025-11-07 19:00:04,682 - INFO] [Epoch 21 | Step 600] Loss 3.9569 (3.6366) | CBR 0.0417 (0.0747) | SNR 1.00 (6.25) | PSNR(recon) 8.761 (9.092) | MSSSIM(recon) 0.231 (0.201) | PSNR(no-noise) 78.556 (80.316) | MSSSIM(no-noise) 0.977 (0.982) | Orth 0.0292 | MSE 1.4813 | MeanReg 0.005329 | Self 1.4016 | NoNoiseRecon 58.8864 | Recon 8649.4229
2025-11-07 19:02:00,432 - INFO] [Epoch 24 | Step 700] Loss 2.8026 (4.9144) | CBR 0.1250 (0.0618) | SNR 4.00 (7.54) | PSNR(recon) 9.858 (9.232) | MSSSIM(recon) 0.207 (0.185) | PSNR(no-noise) 82.362 (79.001) | MSSSIM(no-noise) 0.989 (0.975) | Orth 0.0092 | MSE 1.0896 | MeanReg 0.006192 | Self 1.0599 | NoNoiseRecon 24.5063 | Recon 6717.8926
2025-11-07 19:04:08,238 - INFO] [Epoch 28 | Step 800] Loss 4.4189 (3.6906) | CBR 0.0625 (0.0820) | SNR 10.00 (5.50) | PSNR(recon) 8.104 (9.214) | MSSSIM(recon) 0.130 (0.187) | PSNR(no-noise) 78.690 (80.039) | MSSSIM(no-noise) 0.981 (0.981) | Orth 0.0195 | MSE 1.6998 | MeanReg 0.008949 | Self 1.6446 | NoNoiseRecon 57.1167 | Recon 10060.7734
2025-11-07 19:06:14,694 - INFO] [Epoch 32 | Step 900] Loss 5.0921 (4.7204) | CBR 0.0625 (0.0677) | SNR 1.00 (4.00) | PSNR(recon) 8.863 (9.817) | MSSSIM(recon) 0.172 (0.198) | PSNR(no-noise) 75.167 (77.636) | MSSSIM(no-noise) 0.971 (0.977) | Orth 0.0197 | MSE 1.9741 | MeanReg 0.008667 | Self 1.8896 | NoNoiseRecon 128.6423 | Recon 8448.6953
2025-11-07 19:08:21,888 - INFO] [Epoch 35 | Step 1000] Loss 6.5937 (4.2974) | CBR 0.0208 (0.0667) | SNR 1.00 (7.00) | PSNR(recon) 8.765 (9.365) | MSSSIM(recon) 0.164 (0.188) | PSNR(no-noise) 77.504 (79.752) | MSSSIM(no-noise) 0.961 (0.978) | Orth 0.0805 | MSE 2.3475 | MeanReg 0.007387 | Self 2.1850 | NoNoiseRecon 75.1161 | Recon 8640.8574
2025-11-07 19:10:31,472 - INFO] [Epoch 39 | Step 1100] Loss 2.4584 (4.0639) | CBR 0.1250 (0.0911) | SNR 7.00 (7.75) | PSNR(recon) 8.514 (9.354) | MSSSIM(recon) 0.124 (0.160) | PSNR(no-noise) 83.992 (80.633) | MSSSIM(no-noise) 0.990 (0.983) | Orth 0.0110 | MSE 0.9452 | MeanReg 0.010094 | Self 0.9124 | NoNoiseRecon 16.8294 | Recon 9156.4277
2025-11-07 19:12:34,651 - INFO] [Epoch 42 | Step 1200] Loss 2.0127 (4.1475) | CBR 0.1250 (0.0799) | SNR 1.00 (8.00) | PSNR(recon) 9.995 (9.429) | MSSSIM(recon) 0.253 (0.203) | PSNR(no-noise) 83.056 (80.008) | MSSSIM(no-noise) 0.990 (0.982) | Orth 0.0092 | MSE 0.7741 | MeanReg 0.007390 | Self 0.7414 | NoNoiseRecon 20.8408 | Recon 6509.6768
2025-11-07 19:14:48,527 - INFO] [Epoch 46 | Step 1300] Loss 3.3863 (4.4581) | CBR 0.0833 (0.0660) | SNR 4.00 (8.00) | PSNR(recon) 8.249 (9.008) | MSSSIM(recon) 0.108 (0.180) | PSNR(no-noise) 80.970 (79.137) | MSSSIM(no-noise) 0.987 (0.979) | Orth 0.0134 | MSE 1.3127 | MeanReg 0.010283 | Self 1.2495 | NoNoiseRecon 33.7970 | Recon 9730.6152
2025-11-07 19:16:52,749 - INFO] [Epoch 49 | Step 1400] Loss 3.4741 (4.3964) | CBR 0.0625 (0.0647) | SNR 7.00 (6.46) | PSNR(recon) 9.276 (9.195) | MSSSIM(recon) 0.223 (0.184) | PSNR(no-noise) 80.329 (79.526) | MSSSIM(no-noise) 0.979 (0.978) | Orth 0.0184 | MSE 1.3277 | MeanReg 0.008062 | Self 1.2659 | NoNoiseRecon 38.8212 | Recon 7682.4351
W1107 19:17:17.634000 50982 site-packages/torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGINT death signal, shutting down workers
W1107 19:17:23.552000 50982 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 51001 closing signal SIGINT
W1107 19:17:23.557000 50982 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 51002 closing signal SIGINT
W1107 19:17:23.631000 50982 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 51001 closing signal SIGTERM
W1107 19:17:23.632000 50982 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 51002 closing signal SIGTERM
Traceback (most recent call last):
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 696, in run
    result = self._invoke_run(role)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 855, in _invoke_run
    time.sleep(monitor_interval)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 50982 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 705, in run
    self._shutdown(e.sigval)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 365, in _shutdown
    self._pcontext.close(death_sig)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 572, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 909, in _close
    handler.proc.wait(time_to_wait)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 50982 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 710, in run
    self._shutdown()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 365, in _shutdown
    self._pcontext.close(death_sig)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 572, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 909, in _close
    handler.proc.wait(time_to_wait)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/subprocess.py", line 1953, in _wait
    time.sleep(delay)
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 50982 got signal: 2
Traceback (most recent call last):
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/weakref.py", line 667, in _exitfunc
    f()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/weakref.py", line 591, in __call__
    return info.func(*info.args, **(info.kwargs or {}))
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/library.py", line 402, in _del_library
    handle.destroy()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/_library/utils.py", line 30, in destroy
    self._on_destroy()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/_library/fake_impl.py", line 67, in deregister_fake_class
    self.lib._destroy()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/library.py", line 368, in _destroy
    self.m.reset()
  File "/public/home/sihanwang/miniconda3/envs/dtk2504/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 50982 got signal: 2
